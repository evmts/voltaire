# Comprehensive Performance Comparison: Guillotine vs evmone

## Overview
This document provides a detailed comparison of performance characteristics between Guillotine (our Zig EVM) and evmone's advanced implementation. The analysis focuses on identifying optimization opportunities by examining evmone's design decisions.

## Table of Contents
1. [Execution Entry Points](#execution-entry-points)
2. [Code Analysis Strategy](#code-analysis-strategy)
3. [Memory Management](#memory-management)
4. [Instruction Dispatch](#instruction-dispatch)
5. [Stack Operations](#stack-operations)
6. [Gas Metering](#gas-metering)
7. [Jump Handling](#jump-handling)
8. [Block-Level Optimizations](#block-level-optimizations)
9. [Key Performance Differences](#key-performance-differences)
10. [Actionable Optimizations](#actionable-optimizations)

---

## Code Analysis Strategy

### evmone Advanced Analysis
```cpp
AdvancedCodeAnalysis analyze(evmc_revision rev, bytes_view code) noexcept
{
    // Pre-allocate space for instructions and arguments
    analysis.instrs.reserve(code.size() + 2);
    analysis.push_values.reserve(code.size() + 1);
    
    // Create blocks and instruction sequence
    while (code_pos != code_end) {
        const auto opcode = *code_pos++;
        if (opcode == OP_JUMPDEST) {
            // Close current block and start new one
            analysis.instrs[block.begin_block_index].arg.block = block.close();
        }
        analysis.instrs.emplace_back(opcode_info.fn);
    }
}
```

**Key Optimizations:**
1. **Single-pass analysis**: Builds blocks and instructions in one pass
2. **Pre-allocated vectors**: Reserves memory upfront to avoid reallocations
3. **Instruction objects**: Each instruction is a function pointer + argument
4. **Block metadata in instruction**: Block info stored directly in BEGINBLOCK instruction

### Guillotine Analysis
```zig
pub fn identifyBlocks(allocator: std.mem.Allocator, code: []const u8, jump_table: *const JumpTable) ![]BlockInfo {
    var blocks = std.ArrayList(BlockInfo).init(allocator);
    // Identify block boundaries
    while (i < code.len) {
        // Process opcodes and find boundaries
    }
}

pub fn analyzeBlock(allocator: std.mem.Allocator, code: []const u8, start_pc: u32, end_pc: u32, jump_table: *const JumpTable) !BlockInfo {
    // Separate block analysis pass
}
```

**Current Approach:**
1. **Multi-pass analysis**: Separate passes for blocks and PC mapping
2. **Dynamic allocation**: Uses ArrayList without pre-reservation
3. **Separate structures**: Blocks and PC mapping are separate arrays
4. **Extra indirection**: PC -> block index -> block info

### Performance Differences
- **Memory allocation**: evmone's single allocation vs our multiple allocations
- **Cache locality**: evmone's instruction stream is contiguous
- **Analysis overhead**: Our multi-pass approach has more overhead
- **Runtime lookup**: We need PC->block mapping, evmone doesn't

---

## Execution Entry Points

### evmone Advanced Execution
```cpp
evmc_result execute(AdvancedExecutionState& state, const AdvancedCodeAnalysis& analysis) noexcept
{
    state.analysis.advanced = &analysis;
    const auto* instr = state.analysis.advanced->instrs.data();
    while (instr != nullptr)
        instr = instr->fn(instr, state);
    // ...
}
```

**Key Characteristics:**
1. **Pre-analyzed instructions**: Uses a pre-compiled instruction array with function pointers
2. **Indirect threading**: Each instruction returns the next instruction pointer
3. **No PC tracking**: Instructions chain directly to each other
4. **State separation**: Execution state is separate from analysis

### Guillotine Execution
```zig
pub fn interpret(self: *Vm, contract: *Contract, input: []const u8, is_static: bool) ExecutionError.Error!RunResult {
    // ... setup ...
    var pc: usize = 0;
    while (pc < contract.code_size) {
        const entry = if (pc_to_op_entry_table) |table| 
            table[pc_index]
        else 
            // Build entry on the fly
        // Execute operation
    }
}
```

**Key Characteristics:**
1. **PC-based execution**: Traditional program counter tracking
2. **Lookup table**: Uses PC-to-operation mapping when available
3. **Fallback path**: Can build entries on-the-fly if analysis unavailable
4. **Integrated state**: Contract contains both code and analysis

### Performance Implications
- **evmone's indirect threading** eliminates PC increment overhead and branch prediction misses
- **Function pointer dispatch** allows CPU to prefetch the next instruction
- **No bounds checking** needed since instruction chain is pre-validated
- **Guillotine's PC tracking** adds overhead for increment and bounds checking each iteration

---

## Stack Operations

### evmone Stack Implementation
```cpp
class StackTop
{
    uint256* m_end;  // Pointer to stack end (above top item)
    
    uint256& operator[](int index) noexcept { return m_end[-1 - index]; }
    uint256& top() noexcept { return m_end[-1]; }
    uint256& pop() noexcept { return *--m_end; }
    void push(const uint256& value) noexcept { *m_end++ = value; }
};
```

**Key Optimizations:**
1. **End pointer**: Points above the top item for efficient push/pop
2. **Negative indexing**: Direct array access with no bounds checking
3. **Inline operations**: All operations are single instructions
4. **No size tracking**: Size computed from pointer difference when needed
5. **32-byte aligned**: Uses `std::assume_aligned` for compiler optimization

### Guillotine Stack Implementation
```zig
pub const Stack = @This();
buffer: [CAPACITY]u256,
idx: usize = 0,

pub inline fn pop_unsafe(self: *Stack) u256 {
    self.idx -= 1;
    return self.buffer[self.idx];
}

pub inline fn append_unsafe(self: *Stack, value: u256) void {
    self.buffer[self.idx] = value;
    self.idx += 1;
}
```

**Current Approach:**
1. **Index-based**: Uses index for tracking position
2. **Fixed buffer**: Stack-allocated array
3. **Size tracking**: Maintains explicit index
4. **Safe/unsafe variants**: Separate functions for bounds checking

### Performance Differences
- **Pointer arithmetic vs indexing**: evmone's pointer ops may be faster
- **Stack alignment**: evmone explicitly uses aligned access
- **Size computation**: evmone avoids storing size explicitly
- **Instruction count**: evmone's push/pop are single instructions

---

## Gas Metering

### evmone Gas Handling
```cpp
const Instruction* opx_beginblock(const Instruction* instr, AdvancedExecutionState& state) noexcept
{
    auto& block = instr->arg.block;
    if ((state.gas_left -= block.gas_cost) < 0)
        return state.exit(EVMC_OUT_OF_GAS);
    if (stack_size < block.stack_req)
        return state.exit(EVMC_STACK_UNDERFLOW);
    else if (stack_size + block.stack_max_growth > StackSpace::limit)
        return state.exit(EVMC_STACK_OVERFLOW);
    state.current_block_cost = block.gas_cost;
    return ++instr;
}
```

**Key Optimizations:**
1. **Block-level gas deduction**: Entire block gas cost deducted at once
2. **Stack validation**: All stack checks for the block done upfront
3. **Current block tracking**: For GAS opcode correction
4. **Single branch**: One comparison for gas, stack underflow, and overflow
5. **No per-instruction overhead**: Gas already accounted for

### Guillotine Gas Handling
```zig
// In interpreter loop
if (!block_validated) {
    if (entry.constant_gas > 0) {
        frame.consume_gas(entry.constant_gas) catch |err| break :exec_blk err;
    }
}

// In block validation
frame.consume_gas(block.gas_cost) catch {
    frame.gas_remaining = 0;
    break :exec_blk ExecutionError.Error.OutOfGas;
};
```

**Current Approach:**
1. **Mixed approach**: Block-level when available, per-instruction fallback
2. **Error handling**: Uses Zig error unions
3. **Separate validation**: Stack and gas checked separately
4. **Branch per operation**: Multiple conditional checks

### Performance Differences
- **Validation overhead**: evmone does all checks in one place
- **Branch prediction**: evmone has fewer branches in hot path
- **Gas calculation**: evmone pre-computes all costs during analysis
- **Error handling**: evmone's approach avoids error union overhead

---

## Jump Handling

### evmone Jump Implementation
```cpp
const Instruction* op_jump(const Instruction*, AdvancedExecutionState& state) noexcept
{
    const auto dst = state.stack.pop();
    auto pc = -1;
    if (std::numeric_limits<int>::max() < dst ||
        (pc = find_jumpdest(*state.analysis.advanced, static_cast<int>(dst))) < 0)
        return state.exit(EVMC_BAD_JUMP_DESTINATION);
    return &state.analysis.advanced->instrs[static_cast<size_t>(pc)];
}

const Instruction* op_jumpi(const Instruction* instr, AdvancedExecutionState& state) noexcept
{
    if (state.stack[1] != 0) {
        // Take jump - same as op_jump
        return op_jump(instr, state);
    } else {
        state.stack.pop();  // target
        state.stack.pop();  // condition
        instr = opx_beginblock(instr, state);  // follow-by block
    }
    return instr;
}
```

**Key Optimizations:**
1. **Direct instruction return**: Returns pointer to next instruction
2. **Binary search for JUMPDEST**: Pre-sorted array enables O(log n) lookup
3. **No PC update**: Directly returns instruction pointer
4. **Conditional block validation**: JUMPI validates follow-by block only if not jumping
5. **Stack access pattern**: Checks condition before popping for better prediction

### Guillotine Jump Implementation
```zig
pub fn op_jump(pc: usize, interpreter: Operation.Interpreter, state: Operation.State) !ExecutionResult {
    const frame = state;
    _ = frame.contract.checkAndApplyAsyncAnalysis(vm.allocator);
    const dest = frame.stack.pop_unsafe();
    
    if (!frame.contract.valid_jumpdest(frame.allocator, dest)) {
        return ExecutionError.Error.InvalidJump;
    }
    
    frame.pc = @as(usize, @intCast(dest));
    return ExecutionResult{};
}
```

**Current Approach:**
1. **PC-based**: Updates frame PC instead of returning instruction
2. **Linear search**: JUMPDEST validation uses linear search
3. **Async check**: Checks for async analysis completion
4. **Error unions**: Returns error union instead of direct pointer
5. **Type conversion**: Needs explicit cast from u256 to usize

### Performance Differences
- **Control flow**: evmone's direct return vs our PC update and loop continuation
- **JUMPDEST lookup**: Binary search O(log n) vs linear search O(n)
- **Branch prediction**: evmone's approach better for CPU prediction
- **Function call overhead**: Our approach has more function calls

---

## Instruction Dispatch

### evmone Instruction Model
```cpp
struct Instruction {
    instruction_exec_fn fn = nullptr;
    InstructionArgument arg;
};

// Each instruction is:
using instruction_exec_fn = const Instruction* (*)(const Instruction*, AdvancedExecutionState&);

// Main loop:
while (instr != nullptr)
    instr = instr->fn(instr, state);
```

**Key Design:**
1. **Threaded code**: Each instruction calls the next directly
2. **No switch/dispatch**: Function pointer eliminates dispatch overhead
3. **Instruction chaining**: Pre-linked instruction sequence
4. **Embedded arguments**: Push values, block info stored in instruction
5. **Single parameter**: State passed by reference

### Guillotine Dispatch Model
```zig
// Operation entry in table
pub const TableEntry = struct {
    operation: Operation,
    opcode_byte: u8,
    undefined: bool,
    constant_gas: u16,
    min_stack: u8,
    max_stack: u8,
};

// Main loop:
const entry = table[pc_index];
const res = operation.execute(pc, interpreter, state);
pc += result.bytes_consumed;
```

**Current Design:**
1. **Table lookup**: PC-based indexing into operation table
2. **Indirect call**: Through operation function pointer
3. **Result handling**: Returns execution result with bytes consumed
4. **Separate metadata**: Gas costs and stack requirements separate
5. **Multiple parameters**: PC, interpreter, and state passed

### Performance Analysis
- **Call overhead**: evmone's approach has one less indirection
- **Instruction fetch**: evmone avoids array indexing in hot path
- **Branch prediction**: Linear instruction flow better for CPU
- **Cache locality**: evmone's instruction stream is sequential

---

## Memory Management

### evmone Memory Growth
```cpp
[[gnu::noinline]] inline int64_t grow_memory(
    int64_t gas_left, Memory& memory, uint64_t new_size) noexcept
{
    const auto new_words = num_words(new_size);
    const auto current_words = static_cast<int64_t>(memory.size() / word_size);
    const auto new_cost = 3 * new_words + new_words * new_words / 512;
    const auto current_cost = 3 * current_words + current_words * current_words / 512;
    const auto cost = new_cost - current_cost;
    
    gas_left -= cost;
    if (gas_left >= 0) [[likely]]
        memory.grow(static_cast<size_t>(new_words * word_size));
    return gas_left;
}
```

**Key Optimizations:**
1. **Noinline annotation**: Prevents inlining to keep hot paths small
2. **Direct gas calculation**: Returns updated gas_left directly
3. **Word-based growth**: Always grows to word boundaries
4. **Likely annotation**: Hints successful path to compiler
5. **Cost delta**: Only computes difference in cost

### Guillotine Memory Management
```zig
pub fn expand(self: *Memory, offset: u64, len: u64) MemoryError!u64 {
    if (len == 0) return 0;
    
    const new_size = offset + len;
    if (new_size <= self.data.items.len) return 0;
    
    const new_words = memory.num_words(new_size);
    const current_words = self.data.items.len / 32;
    const gas_cost = self.expansion_cost(current_words, new_words);
    
    try self.data.resize(new_words * 32);
    return gas_cost;
}
```

**Current Approach:**
1. **Error unions**: Returns gas cost through error union
2. **ArrayList**: Uses dynamic array with allocator
3. **Separate resize**: Memory growth separate from gas calculation
4. **Word alignment**: Handled in expansion calculation

### Performance Differences
- **Function structure**: evmone combines gas and growth, we separate them
- **Memory allocation**: evmone likely uses custom allocator
- **Error handling**: Our error unions add overhead
- **Inline control**: evmone carefully controls inlining

---

## GAS Opcode Implementation

### evmone GAS Correction
```cpp
const Instruction* op_gas(const Instruction* instr, AdvancedExecutionState& state) noexcept
{
    const auto correction = state.current_block_cost - instr->arg.number;
    const auto gas = static_cast<uint64_t>(state.gas_left + correction);
    state.stack.push(gas);
    return ++instr;
}
```

**Implementation Details:**
1. **Block cost tracking**: `current_block_cost` set by BEGINBLOCK
2. **Instruction argument**: Gas consumed so far in block stored in instruction
3. **Correction formula**: `actual_gas = gas_left + (block_cost - consumed_so_far)`
4. **Precomputed values**: Correction values computed during analysis

### Guillotine Current Implementation
```zig
pub fn op_gas(pc: usize, interpreter: Operation.Interpreter, state: Operation.State) !ExecutionResult {
    const frame = state;
    const gas = frame.gas_remaining;
    try frame.stack.push(gas);
    return ExecutionResult{ .bytes_consumed = 1 };
}
```

**Missing Features:**
1. **No block correction**: Returns raw gas_left without adjustment
2. **No consumed tracking**: Doesn't account for gas consumed in current block
3. **Inaccurate for block execution**: Will be wrong when block validation is used

### Required Changes
- Track gas consumed within current block
- Store correction values during analysis
- Apply correction formula in GAS opcode

---

## Push Operation Optimizations

### evmone Push Handling
```cpp
// During analysis:
case OP_PUSH1:
case OP_PUSH2:
// ... up to OP_PUSH8:
{
    const auto push_size = static_cast<size_t>(opcode - OP_PUSH1) + 1;
    const uint64_t value = load_push_value(code_pos, push_size);
    instr.arg.small_push_value = value;
    code_pos += push_size;
}

// For larger pushes:
case OP_PUSH9 ... OP_PUSH32:
{
    auto& push_value = analysis.push_values.emplace_back();
    // Copy bytes to dedicated storage
    instr.arg.push_value = &push_value;
}

// During execution:
const Instruction* op_push_small(const Instruction* instr, AdvancedExecutionState& state) noexcept
{
    state.stack.push(instr->arg.small_push_value);
    return ++instr;
}
```

**Key Optimizations:**
1. **Small push optimization**: Values â‰¤ 8 bytes stored directly in instruction
2. **Large push storage**: Separate vector for values > 8 bytes
3. **No PC tracking**: Push value embedded, no need to read from code
4. **Precomputed values**: All push values extracted during analysis
5. **Type specialization**: Different functions for small vs large pushes

### Guillotine Push Implementation
```zig
pub fn op_push(pc: usize, interpreter: Operation.Interpreter, state: Operation.State, n: u8) !ExecutionResult {
    const frame = state;
    const vm = interpreter;
    
    if (pc + 1 + n > frame.contract.code.len) {
        // Handle partial push at end of code
        var value: u256 = 0;
        const available = frame.contract.code.len - pc - 1;
        // Read available bytes
    } else {
        const bytes = frame.contract.code[pc + 1..pc + 1 + n];
        const value = utils.expandToU256(bytes);
        try frame.stack.push(value);
    }
    
    return ExecutionResult{ .bytes_consumed = 1 + n };
}
```

**Current Approach:**
1. **Runtime extraction**: Reads push value from code during execution
2. **Bounds checking**: Validates push doesn't exceed code bounds
3. **PC-based reading**: Uses PC to locate push data
4. **Generic function**: Single function handles all push sizes
5. **Byte expansion**: Converts bytes to u256 at runtime

### Performance Differences
- **Memory access**: evmone avoids code access during execution
- **Value extraction**: evmone pre-extracts vs our runtime extraction
- **Branch prediction**: evmone's approach has no branches in push execution
- **Cache efficiency**: Push values co-located with instructions in evmone

---

## JUMPDEST Validation

### evmone Binary Search
```cpp
inline int find_jumpdest(const AdvancedCodeAnalysis& analysis, int offset) noexcept
{
    const auto begin = std::begin(analysis.jumpdest_offsets);
    const auto end = std::end(analysis.jumpdest_offsets);
    const auto it = std::lower_bound(begin, end, offset);
    return (it != end && *it == offset) ?
               analysis.jumpdest_targets[static_cast<size_t>(it - begin)] :
               -1;
}
```

**Implementation:**
1. **Sorted array**: JUMPDEST offsets maintained in sorted order
2. **Binary search**: Uses std::lower_bound for O(log n) lookup
3. **Dual arrays**: Separate arrays for offsets and instruction indices
4. **Direct indexing**: Maps offset to instruction index directly

### Guillotine Linear Search
```zig
pub fn valid_jumpdest(self: *const Contract, allocator: std.mem.Allocator, dest: u256) bool {
    if (self.analysis) |analysis| {
        if (dest > std.math.maxInt(u32)) return false;
        const dest_u32 = @as(u32, @intCast(dest));
        
        // Linear search through jumpdest positions
        for (analysis.jumpdest_positions) |pos| {
            if (pos == dest_u32) return true;
        }
        return false;
    }
    // Fallback: analyze on demand
}
```

**Current Implementation:**
1. **Linear search**: O(n) search through jumpdest array
2. **On-demand analysis**: Falls back to analysis if not cached
3. **Type conversion**: Converts u256 to u32 for comparison
4. **Simple array**: Single array of positions

### Performance Impact
- **Search complexity**: O(log n) vs O(n) - significant for large contracts
- **Cache misses**: Linear search causes more cache misses
- **Branch prediction**: Binary search has predictable branching pattern

---

## Key Performance Differences

### 1. Execution Model
- **evmone**: Threaded code with direct instruction chaining
- **Guillotine**: Traditional PC-based interpreter loop
- **Impact**: ~2-3x performance difference in instruction dispatch

### 2. Memory Layout
- **evmone**: Instructions, arguments, and metadata co-located
- **Guillotine**: Separate arrays for different data types
- **Impact**: Better cache locality in evmone

### 3. Analysis Strategy
- **evmone**: Single-pass analysis building instruction stream
- **Guillotine**: Multi-pass with separate block identification
- **Impact**: Lower analysis overhead in evmone

### 4. Stack Operations
- **evmone**: Pointer-based with no size tracking
- **Guillotine**: Index-based with explicit size field
- **Impact**: Fewer instructions per stack operation in evmone

### 5. Gas Metering
- **evmone**: Block-level with pre-computed costs
- **Guillotine**: Mixed per-instruction and block approach
- **Impact**: Fewer branches in hot path for evmone

### 6. Error Handling
- **evmone**: Direct status returns, no exceptions
- **Guillotine**: Error unions with explicit error handling
- **Impact**: Less overhead in evmone's approach

---

## Actionable Optimizations

Based on this analysis, here are the highest-impact optimizations we could implement:

### 1. Implement Threaded Code Execution (High Impact)
- Replace PC-based loop with instruction chaining
- Estimated improvement: 2-3x for compute-heavy contracts
- Complexity: High - requires major architectural change

### 2. Pre-extract Push Values (Medium Impact)
- Extract all push values during analysis
- Store small values inline, large values separately
- Estimated improvement: 10-20% for push-heavy contracts
- Complexity: Medium - requires analysis changes

### 3. Binary Search for JUMPDEST (Medium Impact)
- Maintain sorted jumpdest array
- Use binary search for validation
- Estimated improvement: 5-10% for jump-heavy contracts
- Complexity: Low - straightforward algorithm change

### 4. Optimize Stack Implementation (Low Impact)
- Switch to pointer-based stack operations
- Remove size tracking in hot path
- Estimated improvement: 5-10% overall
- Complexity: Medium - requires careful implementation

### 5. Implement GAS Opcode Correction (Low Impact)
- Track gas consumed in current block
- Apply correction in GAS opcode
- Estimated improvement: Correctness fix, minimal performance impact
- Complexity: Low - straightforward implementation

### 6. Combine Gas and Memory Growth (Low Impact)
- Merge gas calculation with memory expansion
- Reduce function call overhead
- Estimated improvement: 2-5% for memory-heavy contracts
- Complexity: Low - function restructuring

---

## Conclusion

evmone achieves its exceptional performance through:
1. **Architectural simplicity**: Threaded code eliminates interpreter overhead
2. **Data locality**: Co-locating related data improves cache efficiency
3. **Minimal branching**: Block-level validation reduces branches in hot paths
4. **Careful optimization**: Every design decision prioritizes performance

The most significant difference is the execution model. While our block-level optimizations have improved performance considerably (5x over baseline), adopting evmone's threaded code approach could potentially yield another 3-5x improvement, bringing us closer to their ~500x performance advantage on complex contracts like snailtracer.
