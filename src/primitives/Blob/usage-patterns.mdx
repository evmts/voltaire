---
title: "Blob Usage Patterns"
---

# Blob Usage Patterns

Common patterns and best practices for working with EIP-4844 blobs.

## Basic Encoding/Decoding

### Single Blob Roundtrip

```typescript
// Encode
const message = new TextEncoder().encode("Hello, blob!");
const blob = Blob.fromData(message);

// Decode
const recovered = Blob.toData(blob);
const text = new TextDecoder().decode(recovered);
// text === "Hello, blob!"
```

### Large Data Handling

```typescript
// Automatic splitting for data > 131KB
const largeData = new Uint8Array(300000);

// Split into multiple blobs
const blobs = Blob.splitData(largeData);
console.log(`Split into ${blobs.length} blobs`); // 3

// Reconstruct
const reconstructed = Blob.joinData(blobs);
// reconstructed equals largeData
```

---

## Transaction Creation

### Complete Blob Transaction Workflow

```typescript
async function createBlobTransaction(data: Uint8Array) {
  // 1. Estimate and validate
  const blobCount = Blob.estimateBlobCount(data.length);
  if (blobCount > Blob.MAX_PER_TRANSACTION) {
    throw new Error(`Data requires ${blobCount} blobs (max 6)`);
  }

  // 2. Calculate gas
  const blobGas = Blob.calculateGas(blobCount);
  console.log(`Blob gas: ${blobGas}`);

  // 3. Split data into blobs
  const blobs = Blob.splitData(data);

  // 4. Generate commitments (when implemented)
  // const commitments = blobs.map(b => Blob.toCommitment(b));

  // 5. Generate proofs (when implemented)
  // const proofs = blobs.map((b, i) => Blob.toProof(b, commitments[i]));

  // 6. Verify batch (when implemented)
  // const isValid = Blob.verifyBatch(blobs, commitments, proofs);
  // if (!isValid) throw new Error("Invalid proofs");

  // 7. Create versioned hashes
  // const versionedHashes = commitments.map(c => Blob.toVersionedHash(c));

  // 8. Build transaction
  return {
    type: 0x03, // EIP-4844
    chainId: 1,
    nonce: 0,
    maxPriorityFeePerGas: 1000000000n,
    maxFeePerGas: 20000000000n,
    maxFeePerBlobGas: 1000000000n,
    gasLimit: 21000n,
    to: '0x...',
    value: 0n,
    data: '0x',
    // blobVersionedHashes: versionedHashes,
    // Network layer:
    // blobs: blobs,
    // commitments: commitments,
    // proofs: proofs,
  };
}
```

### Pre-flight Validation

```typescript
function validateTransactionData(data: Uint8Array): void {
  // Size check
  const blobCount = Blob.estimateBlobCount(data.length);
  if (blobCount > Blob.MAX_PER_TRANSACTION) {
    throw new Error(
      `Data too large: requires ${blobCount} blobs (max ${Blob.MAX_PER_TRANSACTION})`
    );
  }

  // Cost estimation
  const blobGas = Blob.calculateGas(blobCount);
  const maxBlobGas = Blob.calculateGas(Blob.MAX_PER_TRANSACTION);

  console.log(`Transaction will use ${blobCount}/${Blob.MAX_PER_TRANSACTION} blobs`);
  console.log(`Blob gas: ${blobGas}/${maxBlobGas}`);

  if (blobGas > Blob.TARGET_GAS_PER_BLOCK) {
    console.warn("Transaction exceeds target gas per block");
  }
}
```

---

## Data Processing

### Stream to Blobs

```typescript
async function streamToBlobs(
  stream: ReadableStream<Uint8Array>
): Promise<BrandedBlob[]> {
  const chunks: Uint8Array[] = [];
  let totalSize = 0;

  const maxSize = (Blob.SIZE - 8) * Blob.MAX_PER_TRANSACTION;
  const reader = stream.getReader();

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      totalSize += value.length;
      if (totalSize > maxSize) {
        throw new Error("Stream exceeds max transaction size");
      }

      chunks.push(value);
    }
  } finally {
    reader.releaseLock();
  }

  // Combine chunks
  const combined = new Uint8Array(totalSize);
  let offset = 0;
  for (const chunk of chunks) {
    combined.set(chunk, offset);
    offset += chunk.length;
  }

  return Blob.splitData(combined);
}
```

### Progressive Decoding

```typescript
function processLargeBlob(blobs: BrandedBlob[]): void {
  for (const blob of blobs) {
    const chunk = Blob.toData(blob);

    // Process chunk immediately (streaming)
    processChunk(chunk);

    // Don't accumulate all data in memory
  }
}

function processChunk(chunk: Uint8Array): void {
  // Process data chunk by chunk
  console.log(`Processing ${chunk.length} bytes`);
}
```

### Batch Operations

```typescript
function batchEncodeFiles(files: File[]): Promise<BrandedBlob[][]> {
  return Promise.all(
    files.map(async (file) => {
      const data = new Uint8Array(await file.arrayBuffer());

      // Validate size
      const count = Blob.estimateBlobCount(data.length);
      if (count > Blob.MAX_PER_TRANSACTION) {
        throw new Error(`File "${file.name}" too large`);
      }

      return Blob.splitData(data);
    })
  );
}
```

---

## Gas Estimation

### Calculate Transaction Cost

```typescript
function estimateBlobCost(
  dataSize: number,
  blobBaseFee: bigint
): { blobCount: number; blobGas: number; totalCost: bigint } {
  // Estimate blobs needed
  const blobCount = Blob.estimateBlobCount(dataSize);

  // Calculate gas
  const blobGas = Blob.calculateGas(blobCount);

  // Calculate cost (blob gas Ã— blob base fee)
  const totalCost = BigInt(blobGas) * blobBaseFee;

  return { blobCount, blobGas, totalCost };
}

// Usage
const cost = estimateBlobCost(300000, 1000000000n);
console.log(`${cost.blobCount} blobs, ${cost.blobGas} gas, ${cost.totalCost} wei`);
```

### Compare Blob vs Calldata Cost

```typescript
function compareDataAvailability(dataSize: number): {
  blob: { blobs: number; gas: number; costWei: bigint };
  calldata: { gas: number; costWei: bigint };
} {
  // Blob cost
  const blobCount = Blob.estimateBlobCount(dataSize);
  const blobGas = Blob.calculateGas(blobCount);
  const blobBaseFee = 1000000000n; // Example: 1 gwei
  const blobCost = BigInt(blobGas) * blobBaseFee;

  // Calldata cost (16 gas per non-zero byte, 4 per zero byte)
  // Assume worst case: all non-zero
  const calldataGas = dataSize * 16;
  const gasPrice = 20000000000n; // Example: 20 gwei
  const calldataCost = BigInt(calldataGas) * gasPrice;

  return {
    blob: { blobs: blobCount, gas: blobGas, costWei: blobCost },
    calldata: { gas: calldataGas, costWei: calldataCost },
  };
}

// Usage
const comparison = compareDataAvailability(100000);
console.log("Blob:", comparison.blob);
console.log("Calldata:", comparison.calldata);
console.log("Savings:", comparison.calldata.costWei - comparison.blob.costWei);
```

---

## Validation Patterns

### Comprehensive Validation

```typescript
interface BlobTransaction {
  blobs: Uint8Array[];
  commitments: Uint8Array[];
  proofs: Uint8Array[];
  blobVersionedHashes: Uint8Array[];
}

function validateBlobTransaction(tx: BlobTransaction): void {
  // Count validation
  if (tx.blobs.length === 0) {
    throw new Error("No blobs in transaction");
  }
  if (tx.blobs.length > Blob.MAX_PER_TRANSACTION) {
    throw new Error(`Too many blobs: ${tx.blobs.length}`);
  }

  // Array length consistency
  if (
    tx.blobs.length !== tx.commitments.length ||
    tx.blobs.length !== tx.proofs.length ||
    tx.blobs.length !== tx.blobVersionedHashes.length
  ) {
    throw new Error("Mismatched array lengths");
  }

  // Validate each blob
  for (let i = 0; i < tx.blobs.length; i++) {
    if (!Blob.isValid(tx.blobs[i])) {
      throw new Error(`Invalid blob at index ${i}`);
    }
  }

  // Validate commitments
  for (let i = 0; i < tx.commitments.length; i++) {
    if (!Blob.Commitment.isValid(tx.commitments[i])) {
      throw new Error(`Invalid commitment at index ${i}`);
    }
  }

  // Validate proofs
  for (let i = 0; i < tx.proofs.length; i++) {
    if (!Blob.Proof.isValid(tx.proofs[i])) {
      throw new Error(`Invalid proof at index ${i}`);
    }
  }

  // Validate versioned hashes
  for (let i = 0; i < tx.blobVersionedHashes.length; i++) {
    if (!Blob.VersionedHash.isValid(tx.blobVersionedHashes[i])) {
      throw new Error(`Invalid versioned hash at index ${i}`);
    }
  }

  // Verify proofs (when implemented)
  // const isValid = Blob.verifyBatch(tx.blobs, tx.commitments, tx.proofs);
  // if (!isValid) throw new Error("Proof verification failed");

  console.log("Transaction validation passed");
}
```

### Type-Safe Validation

```typescript
function ensureValidBlob(data: Uint8Array): BrandedBlob {
  if (!Blob.isValid(data)) {
    throw new Error(`Invalid blob: ${data.length} bytes`);
  }
  return data as BrandedBlob;
}

function ensureValidCommitment(data: Uint8Array): Commitment {
  if (!Blob.Commitment.isValid(data)) {
    throw new Error(`Invalid commitment: ${data.length} bytes`);
  }
  return data;
}

function ensureValidProof(data: Uint8Array): Proof {
  if (!Blob.Proof.isValid(data)) {
    throw new Error(`Invalid proof: ${data.length} bytes`);
  }
  return data;
}

function ensureValidVersionedHash(data: Uint8Array): VersionedHash {
  if (!Blob.VersionedHash.isValid(data)) {
    throw new Error("Invalid versioned hash");
  }
  return data;
}
```

---

## Performance Optimization

### WASM Acceleration

```typescript
import { isWasmBlobAvailable, fromDataWasm, toDataWasm } from './Blob.wasm.js';
import { fromData, toData } from './BrandedBlob/index.js';

// Choose implementation based on availability
const encode = isWasmBlobAvailable() ? fromDataWasm : fromData;
const decode = isWasmBlobAvailable() ? toDataWasm : toData;

// Use in performance-critical paths
function processMany(datasets: Uint8Array[]): Uint8Array[] {
  const blobs = datasets.map(encode);
  return blobs.map(decode);
}
```

### Memory-Efficient Processing

```typescript
// Bad: Accumulates all in memory
function processBlobsBad(blobs: BrandedBlob[]): Uint8Array {
  const allData = blobs.map(Blob.toData);
  const combined = Blob.joinData(blobs);
  return combined; // Held 2x data in memory
}

// Good: Process incrementally
function processBlobsGood(blobs: BrandedBlob[]): Uint8Array {
  const chunks: Uint8Array[] = [];

  for (const blob of blobs) {
    const chunk = Blob.toData(blob);
    processChunk(chunk); // Process immediately
    chunks.push(chunk);
  }

  // Combine only when needed
  return Blob.joinData(blobs);
}
```

### Batch Processing

```typescript
// Process in chunks to control memory usage
async function processBlobsInBatches(
  blobs: BrandedBlob[],
  batchSize: number = 10
): Promise<void> {
  for (let i = 0; i < blobs.length; i += batchSize) {
    const batch = blobs.slice(i, i + batchSize);

    // Process batch
    await Promise.all(
      batch.map(async (blob) => {
        const data = Blob.toData(blob);
        await processBlobData(data);
      })
    );

    // Allow GC between batches
    await new Promise(resolve => setTimeout(resolve, 0));
  }
}
```

---

## Error Handling

### Graceful Degradation

```typescript
function safeSplitData(data: Uint8Array): BrandedBlob[] | null {
  try {
    return Blob.splitData(data);
  } catch (err) {
    if (err.message.includes("Data too large")) {
      console.error("Data exceeds max transaction size");
      return null;
    }
    throw err; // Re-throw unexpected errors
  }
}
```

### Validation with Context

```typescript
class BlobValidationError extends Error {
  constructor(
    message: string,
    public readonly context: { index?: number; field?: string }
  ) {
    super(message);
    this.name = "BlobValidationError";
  }
}

function validateBlobWithContext(
  blob: Uint8Array,
  index: number
): BrandedBlob {
  if (!Blob.isValid(blob)) {
    throw new BlobValidationError("Invalid blob size", {
      index,
      field: "blob",
    });
  }
  return blob as BrandedBlob;
}
```

---

## Testing Patterns

### Roundtrip Tests

```typescript
import { describe, it, expect } from 'vitest';

describe('Blob roundtrip', () => {
  it('should preserve data through encode/decode', () => {
    const original = new Uint8Array([1, 2, 3, 4, 5]);
    const blob = Blob.fromData(original);
    const recovered = Blob.toData(blob);

    expect(recovered).toEqual(original);
  });

  it('should handle large data with split/join', () => {
    const original = new Uint8Array(300000);
    for (let i = 0; i < original.length; i++) {
      original[i] = i % 256;
    }

    const blobs = Blob.splitData(original);
    const recovered = Blob.joinData(blobs);

    expect(recovered).toEqual(original);
  });
});
```

### Gas Calculation Tests

```typescript
describe('Blob gas calculations', () => {
  it('should calculate correct gas', () => {
    expect(Blob.calculateGas(0)).toBe(0);
    expect(Blob.calculateGas(1)).toBe(131072);
    expect(Blob.calculateGas(3)).toBe(393216); // Target
    expect(Blob.calculateGas(6)).toBe(786432); // Max
  });

  it('should estimate blob count correctly', () => {
    expect(Blob.estimateBlobCount(0)).toBe(0);
    expect(Blob.estimateBlobCount(1000)).toBe(1);
    expect(Blob.estimateBlobCount(131064)).toBe(1);
    expect(Blob.estimateBlobCount(131065)).toBe(2);
    expect(Blob.estimateBlobCount(300000)).toBe(3);
  });
});
```

---

## See Also

- [index.mdx](./index.mdx) - Main Blob overview
- [constructors.mdx](./constructors.mdx) - Constructor patterns
- [validation.mdx](./validation.mdx) - Validation patterns
- [utilities.mdx](./utilities.mdx) - Utility functions
- [wasm.mdx](./wasm.mdx) - WASM acceleration
