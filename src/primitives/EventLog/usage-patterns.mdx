---
title: EventLog Usage Patterns
description: Real-world patterns for working with Ethereum event logs
---

import { Aside } from '@astrojs/starlight/components';

# Usage Patterns

Real-world examples demonstrating common patterns for working with Ethereum event logs.

## ERC-20 Token Transfers

### Parse Transfer Events

```typescript
import * as EventLog from '@tevm/primitives/EventLog'
import * as Hash from '@tevm/primitives/Hash'
import * as Address from '@tevm/primitives/Address'
import * as Abi from '@tevm/primitives/Abi'

// Transfer(address indexed from, address indexed to, uint256 value)
const TRANSFER_SIG = Hash.from(
  "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
)

interface Transfer {
  from: Address
  to: Address
  value: bigint
  log: EventLog
}

function parseTransfer(log: BrandedEventLog): Transfer {
  const [fromHash, toHash] = EventLog.getIndexedTopics(log)

  // Convert 32-byte topic hashes to 20-byte addresses
  const from = Address.fromBytes(fromHash.slice(12))
  const to = Address.fromBytes(toHash.slice(12))

  // Decode non-indexed uint256 value from data
  const [value] = Abi.decodeParameters(
    [{ type: 'uint256' }],
    log.data
  ) as [bigint]

  return { from, to, value, log }
}

// Find all transfers
const transferLogs = EventLog.filterLogs(allLogs, {
  address: tokenAddress,
  topics: [TRANSFER_SIG]
})

const transfers = transferLogs.map(parseTransfer)
```

### Track User Token Balance

```typescript
function calculateBalance(
  logs: BrandedEventLog[],
  tokenAddress: BrandedAddress,
  userAddress: BrandedAddress
): bigint {
  const userHash = Hash.from("0x000000000000000000000000" + userAddress.slice(2))

  // Get all transfers involving user
  const userLogs = EventLog.filterLogs(logs, {
    address: tokenAddress,
    topics: [
      TRANSFER_SIG,
      [userHash, null], // from user OR anyone
      [userHash, null]  // to user OR anyone
    ]
  })

  let balance = 0n

  for (const log of userLogs) {
    const [fromHash, toHash] = EventLog.getIndexedTopics(log)
    const [value] = Abi.decodeParameters([{ type: 'uint256' }], log.data) as [bigint]

    const fromUser = Hash.equals(fromHash, userHash)
    const toUser = Hash.equals(toHash, userHash)

    if (fromUser && !toUser) {
      balance -= value  // User sent tokens
    } else if (!fromUser && toUser) {
      balance += value  // User received tokens
    }
    // If fromUser && toUser, user sent to self (net zero)
  }

  return balance
}
```

### Find Large Transfers

```typescript
function findLargeTransfers(
  logs: BrandedEventLog[],
  minAmount: bigint
): Transfer[] {
  const transferLogs = EventLog.filterLogs(logs, {
    topics: [TRANSFER_SIG]
  })

  return transferLogs
    .map(parseTransfer)
    .filter(transfer => transfer.value >= minAmount)
    .sort((a, b) => Number(b.value - a.value))  // Descending by value
}
```

## Uniswap Swaps

### Parse Swap Events

```typescript
// Swap(address indexed sender, uint amount0In, uint amount1In, uint amount0Out, uint amount1Out, address indexed to)
const SWAP_SIG = Hash.from(
  "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822"
)

interface Swap {
  sender: Address
  to: Address
  amount0In: bigint
  amount1In: bigint
  amount0Out: bigint
  amount1Out: bigint
  log: EventLog
}

function parseSwap(log: BrandedEventLog): Swap {
  const [senderHash, toHash] = EventLog.getIndexedTopics(log)

  const sender = Address.fromBytes(senderHash.slice(12))
  const to = Address.fromBytes(toHash.slice(12))

  const [amount0In, amount1In, amount0Out, amount1Out] = Abi.decodeParameters(
    [
      { type: 'uint256' },
      { type: 'uint256' },
      { type: 'uint256' },
      { type: 'uint256' }
    ],
    log.data
  ) as [bigint, bigint, bigint, bigint]

  return { sender, to, amount0In, amount1In, amount0Out, amount1Out, log }
}
```

### Track Pair Volume

```typescript
function calculatePairVolume(
  logs: BrandedEventLog[],
  pairAddress: BrandedAddress
): { volume0: bigint; volume1: bigint } {
  const swapLogs = EventLog.filterLogs(logs, {
    address: pairAddress,
    topics: [SWAP_SIG]
  })

  let volume0 = 0n
  let volume1 = 0n

  for (const log of swapLogs) {
    const swap = parseSwap(log)
    volume0 += swap.amount0In + swap.amount0Out
    volume1 += swap.amount1In + swap.amount1Out
  }

  return { volume0, volume1 }
}
```

## NFT Transfers (ERC-721)

### Parse NFT Transfer Events

```typescript
// Transfer(address indexed from, address indexed to, uint256 indexed tokenId)
const NFT_TRANSFER_SIG = Hash.from(
  "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
)

interface NFTTransfer {
  from: Address
  to: Address
  tokenId: bigint
  log: EventLog
}

function parseNFTTransfer(log: BrandedEventLog): NFTTransfer {
  const [fromHash, toHash, tokenIdHash] = log.topics

  const from = Address.fromBytes(fromHash.slice(12))
  const to = Address.fromBytes(toHash.slice(12))

  // tokenId is in topic3 (indexed uint256)
  const tokenId = BigInt(Hex.fromBytes(tokenIdHash))

  return { from, to, tokenId, log }
}

// Find all transfers of specific NFT
function getNFTHistory(
  logs: BrandedEventLog[],
  collectionAddress: BrandedAddress,
  tokenId: bigint
): NFTTransfer[] {
  const tokenIdHash = Hash.fromNumber(tokenId)

  const transfers = EventLog.filterLogs(logs, {
    address: collectionAddress,
    topics: [NFT_TRANSFER_SIG, null, null, tokenIdHash]
  })

  return EventLog.sortLogs(transfers).map(parseNFTTransfer)
}

// Find current owner
function getCurrentOwner(
  logs: BrandedEventLog[],
  collectionAddress: BrandedAddress,
  tokenId: bigint
): Address | null {
  const history = getNFTHistory(logs, collectionAddress, tokenId)

  if (history.length === 0) return null

  // Last transfer's 'to' address is current owner
  return history[history.length - 1].to
}
```

## Chain Reorganization Handling

### Filter Valid Logs

```typescript
function getValidLogs(logs: BrandedEventLog[]): BrandedEventLog[] {
  return logs.filter(log => !EventLog.isRemoved(log))
}
```

### Detect and Handle Reorgs

```typescript
interface ReorgHandler {
  onLogsAdded: (logs: BrandedEventLog[]) => void
  onLogsRemoved: (logs: BrandedEventLog[]) => void
}

function processLogUpdate(
  newLogs: BrandedEventLog[],
  handler: ReorgHandler
): void {
  const added = newLogs.filter(log => !log.removed)
  const removed = newLogs.filter(log => log.removed)

  if (removed.length > 0) {
    handler.onLogsRemoved(removed)
  }

  if (added.length > 0) {
    handler.onLogsAdded(added)
  }
}
```

### Maintain Consistent State

```typescript
class LogCache {
  private logs = new Map<string, BrandedEventLog>()

  private getKey(log: BrandedEventLog): string {
    return `${log.blockNumber}-${log.transactionIndex}-${log.logIndex}`
  }

  add(logs: BrandedEventLog[]): void {
    for (const log of logs) {
      if (!EventLog.isRemoved(log)) {
        this.logs.set(this.getKey(log), log)
      }
    }
  }

  remove(logs: BrandedEventLog[]): void {
    for (const log of logs) {
      this.logs.delete(this.getKey(log))
    }
  }

  getAll(): BrandedEventLog[] {
    return EventLog.sortLogs([...this.logs.values()])
  }

  query(filter: Filter): BrandedEventLog[] {
    return EventLog.filterLogs(this.getAll(), filter)
  }
}
```

## Multi-Contract Event Monitoring

### Track Multiple Token Transfers

```typescript
function trackMultipleTokens(
  logs: BrandedEventLog[],
  tokenAddresses: BrandedAddress[]
): Map<string, BrandedEventLog[]> {
  const byToken = new Map<string, BrandedEventLog[]>()

  for (const tokenAddress of tokenAddresses) {
    const key = Hex.fromBytes(tokenAddress)

    const tokenLogs = EventLog.filterLogs(logs, {
      address: tokenAddress,
      topics: [TRANSFER_SIG]
    })

    byToken.set(key, tokenLogs)
  }

  return byToken
}
```

### Monitor Protocol Events

```typescript
const PROTOCOL_CONTRACTS = {
  router: routerAddress,
  factory: factoryAddress,
  pairs: [pair1, pair2, pair3]
}

function getProtocolLogs(
  logs: BrandedEventLog[]
): Record<string, BrandedEventLog[]> {
  return {
    router: EventLog.filterLogs(logs, {
      address: PROTOCOL_CONTRACTS.router
    }),
    factory: EventLog.filterLogs(logs, {
      address: PROTOCOL_CONTRACTS.factory
    }),
    pairs: EventLog.filterLogs(logs, {
      address: PROTOCOL_CONTRACTS.pairs
    })
  }
}
```

## Event Indexing

### Build Event Index

```typescript
class EventIndex {
  private bySignature = new Map<string, BrandedEventLog[]>()
  private byAddress = new Map<string, BrandedEventLog[]>()
  private byBlock = new Map<bigint, BrandedEventLog[]>()

  index(logs: BrandedEventLog[]): void {
    for (const log of logs) {
      // Index by signature
      const sig = EventLog.getTopic0(log)
      if (sig) {
        const sigKey = Hex.fromBytes(sig)
        const sigLogs = this.bySignature.get(sigKey) ?? []
        sigLogs.push(log)
        this.bySignature.set(sigKey, sigLogs)
      }

      // Index by address
      const addrKey = Hex.fromBytes(log.address)
      const addrLogs = this.byAddress.get(addrKey) ?? []
      addrLogs.push(log)
      this.byAddress.set(addrKey, addrLogs)

      // Index by block
      if (log.blockNumber !== undefined) {
        const blockLogs = this.byBlock.get(log.blockNumber) ?? []
        blockLogs.push(log)
        this.byBlock.set(log.blockNumber, blockLogs)
      }
    }
  }

  getBySignature(sig: BrandedHash): BrandedEventLog[] {
    const key = Hex.fromBytes(sig)
    return this.bySignature.get(key) ?? []
  }

  getByAddress(addr: BrandedAddress): BrandedEventLog[] {
    const key = Hex.fromBytes(addr)
    return this.byAddress.get(key) ?? []
  }

  getByBlock(blockNumber: bigint): BrandedEventLog[] {
    return this.byBlock.get(blockNumber) ?? []
  }
}
```

## Pagination

### Fetch Logs in Chunks

```typescript
async function fetchLogsInChunks(
  provider: Provider,
  filter: Filter,
  chunkSize: bigint
): Promise<BrandedEventLog[]> {
  const allLogs: BrandedEventLog[] = []

  let fromBlock = filter.fromBlock ?? 0n
  const toBlock = filter.toBlock ?? await provider.getBlockNumber()

  while (fromBlock <= toBlock) {
    const chunkEnd = fromBlock + chunkSize - 1n
    const actualEnd = chunkEnd > toBlock ? toBlock : chunkEnd

    const logs = await provider.getLogs({
      ...filter,
      fromBlock,
      toBlock: actualEnd
    })

    allLogs.push(...logs)
    fromBlock = actualEnd + 1n
  }

  return EventLog.sortLogs(allLogs)
}
```

<Aside type="tip" title="Performance Optimization">
When filtering large log datasets, filter by address first (fastest), then topics, then block range. Use indexed lookups when possible.
</Aside>

## Advanced Patterns

### Event Aggregation

```typescript
interface DailyVolume {
  date: string
  volume: bigint
  txCount: number
}

function aggregateDailyVolume(
  logs: BrandedEventLog[]
): DailyVolume[] {
  const byDay = new Map<string, { volume: bigint; txCount: number }>()

  for (const log of logs) {
    if (!log.blockNumber) continue

    const swap = parseSwap(log)
    const date = getDateFromBlock(log.blockNumber)

    const current = byDay.get(date) ?? { volume: 0n, txCount: 0 }
    current.volume += swap.amount0In + swap.amount0Out
    current.txCount++

    byDay.set(date, current)
  }

  return Array.from(byDay.entries())
    .map(([date, data]) => ({ date, ...data }))
    .sort((a, b) => a.date.localeCompare(b.date))
}
```

### Real-time Event Stream

```typescript
class EventStream {
  private handlers = new Map<string, (log: BrandedEventLog) => void>()

  on(eventSig: BrandedHash, handler: (log: BrandedEventLog) => void): void {
    const key = Hex.fromBytes(eventSig)
    this.handlers.set(key, handler)
  }

  async process(log: BrandedEventLog): Promise<void> {
    const sig = EventLog.getTopic0(log)
    if (!sig) return

    const key = Hex.fromBytes(sig)
    const handler = this.handlers.get(key)

    if (handler && !EventLog.isRemoved(log)) {
      await handler(log)
    }
  }
}

// Usage
const stream = new EventStream()

stream.on(TRANSFER_SIG, async (log) => {
  const transfer = parseTransfer(log)
  await processTransfer(transfer)
})

stream.on(SWAP_SIG, async (log) => {
  const swap = parseSwap(log)
  await processSwap(swap)
})
```

## See Also

- [Constructors](/primitives/eventlog/constructors) - Creating event logs
- [Validation](/primitives/eventlog/validation) - Matching and validation
- [Utilities](/primitives/eventlog/utilities) - Filtering and sorting
- [WASM](/primitives/eventlog/wasm) - Performance optimization
